{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## todo fix classes and labels code in detection.py\n",
    "##tflite tends to give garbage classes to null detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE - TEST MODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "import itertools\n",
    "\n",
    "\n",
    "def get_pixel_scaler(rects,person_width,resolution):\n",
    "    top_line=[[0.0, 0.4], [1.0, 0.4]]\n",
    "\n",
    "    bot_line=[[0.0, 0.6], [1.0, 0.6]]\n",
    "    \n",
    "    centroid_list=[]\n",
    "\n",
    "\n",
    "    for (i, (ymin, xmin, ymax, xmax)) in enumerate(rects):\n",
    "               # use the bounding box coordinates to derive the centroid\n",
    "                cx = int((xmin + xmax) / 2.0)\n",
    "                cy = int((ymin + ymax) / 2.0)\n",
    "                centroids=(cx, cy)\n",
    "                \n",
    "                norm_cy=cy/resolution[1]\n",
    "                \n",
    "                if norm_cy>=0.4 and norm_cy<=0.6:\n",
    "                   \n",
    "                    \n",
    "                    if xmax-xmin>= ymax-ymin:\n",
    "                        dist=xmax-xmin\n",
    "                    else:\n",
    "                        dist=ymax-ymin\n",
    "                    \n",
    "                    person_width.append(dist)    \n",
    "                    \n",
    "    \n",
    "    \n",
    "    return person_width\n",
    "\n",
    "def get_box_width(rects,pixel_scale):\n",
    "\n",
    "    \n",
    "    centroid_list=[]\n",
    "    for (i, (ymin, xmin, ymax, xmax)) in enumerate(rects):\n",
    "        # use the bounding box coordinates to derive the centroid\n",
    "        \n",
    "        x_scaled=(xmax-xmin)*pixel_scale\n",
    "        y_scaled=(ymax-ymin)*pixel_scale\n",
    "        x_scaled=round(x_scaled)\n",
    "        y_scaled=round(y_scaled)\n",
    "        \n",
    "        cx = int((xmin + xmax) / 2.0)\n",
    "        cy = int((ymin + ymax) / 2.0)\n",
    "        \n",
    "        centroid_list.append([[[xmax,cy],[cx,ymax]],[x_scaled,y_scaled]])\n",
    "    return centroid_list\n",
    "               \n",
    "def compute_distance(image,rects,pixel_scale,thresh=20):\n",
    "    centroid_list=[]\n",
    "    \n",
    "    for (i, (ymin, xmin, ymax, xmax)) in enumerate(rects):\n",
    "        cx = int((xmin + xmax) / 2.0)\n",
    "        cy = int((ymin + ymax) / 2.0)\n",
    "        \n",
    "        centroid_list.append([cx,cy])\n",
    "        \n",
    "    for a,b in list(itertools.combinations(range(len(centroid_list)), 2)):\n",
    "        ca=centroid_list[a]\n",
    "        cb=centroid_list[b]\n",
    "        \n",
    "        point_dist=dist.euclidean(ca,cb)*pixel_scale\n",
    "        \n",
    "        if point_dist<=thresh:\n",
    "            mid_x=int((ca[0]+cb[0])/2)\n",
    "            mid_y=int((ca[1]+cb[1])/2)\n",
    "            cv2.putText(image, 'ALERT',( mid_x,mid_y),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1)\n",
    "            cv2.line(image, tuple(ca), tuple(cb),(0,0,255), 1)\n",
    "        else:\n",
    "            mid_x=int((ca[0]+cb[0])/2)\n",
    "            mid_y=int((ca[1]+cb[1])/2)\n",
    "            cv2.putText(image, '{} inch'.format(int(point_dist)),( mid_x,mid_y),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0,255, 255), 1)\n",
    "        \n",
    "            cv2.line(image, tuple(ca), tuple(cb),(0,255,255), 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    return image\n",
    "            \n",
    "def draw_dist(objects,image):\n",
    "    #cv2.line(image, self.line_points[0],self.line_points[1], (0, 255, 255), 2)\n",
    "\n",
    "    for centroid,scaler in objects:\n",
    "        \n",
    "        \n",
    "        text = \"{} inch\".format(int(scaler[0]))\n",
    "        cv2.putText(image, text, (centroid[0][0], centroid[0][1]+5),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "        text = \"{} inch\".format(int(scaler[1]))\n",
    "        cv2.putText(image, text, (centroid[1][0]+5 , centroid[1][1]),cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 255, 0), 1)\n",
    "        \n",
    "        #cv2.putText(image, 'dist', (centroid[0] + 10, centroid[1] + 10),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "        \n",
    "\n",
    "    # loop over the info tuples and draw them on our frame\n",
    "    #info = [(\"Up\", self.totalUp),(\"Down\", self.totalDown)]\n",
    "    #for (i, (k, v)) in enumerate(info):\n",
    "    #    text = \"{}: {}\".format(k, v)\n",
    "    #    cv2.putText(image, text, (10, h - ((i * 20) + 20)),cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    return image\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracking import Tracking\n",
    "from detection import Detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "wait_time=[]\n",
    "list_centroids=[]\n",
    "\n",
    "def streaming(video_path,resolution=(300,240),color=True,\n",
    "              model_kwargs={},\n",
    "              det_kwargs={},\n",
    "              track_kwargs={},\n",
    "              track=True,draw=True,\n",
    "              output_path=None,display=False,new_fps=None):\n",
    "    \n",
    "    \n",
    "    record= True if output_path is not None else False\n",
    "    dist=True\n",
    "    #initialize model detection\n",
    "    det=Detection()\n",
    "    det.load_model(**model_kwargs)\n",
    "    \n",
    "    #if tflite, force resolution to tflite model resolution\n",
    "    if det.tflite:\n",
    "        resolution=det.resolution\n",
    "        \n",
    "    #initialize model tracking\n",
    "    if track:\n",
    "        trk=Tracking(resolution,**track_kwargs)\n",
    "     \n",
    "    print('W {}, H {}'.format(resolution[0],resolution[1]))\n",
    "    \n",
    "    if record:\n",
    "        output_dir=os.path.split(output_path)[0]\n",
    "        os.makedirs(output_dir) if not os.path.exists(output_dir) else None\n",
    "        output_fps=10\n",
    "        vid = cv2.VideoWriter(output_path,cv2.VideoWriter_fourcc(*\"XVID\"), output_fps, resolution, True)\n",
    "        \n",
    "\n",
    "    \n",
    "    if video_path is not None and new_fps is not None:\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        movie_fps=int(cap.get(int(cv2.CAP_PROP_FPS)))\n",
    "        cap.release()\n",
    "        eq_space=np.linspace(1,movie_fps,num=new_fps,dtype='int')\n",
    "        skip_frame=0\n",
    "        \n",
    "    person_width=[]    \n",
    "    prev_u=0\n",
    "    prev_d=0\n",
    "    \n",
    "    \n",
    "    for frame,fps in stream_video(video_path,resolution):\n",
    "\n",
    "            if video_path is not None and new_fps is not None:\n",
    "                if skip_frame>=movie_fps:\n",
    "                    skip_frame=0\n",
    "\n",
    "                skip_frame+=1\n",
    "\n",
    "                if skip_frame not in eq_space.tolist():\n",
    "                    continue\n",
    "\n",
    "\n",
    "            frame,image=det.transform_image(frame,resolution)\n",
    "\n",
    "            results=det.model_inference(image)\n",
    "\n",
    "            results=det.filter_boxes(results,**det_kwargs)\n",
    "\n",
    "            results=det.scale_boxes(results,resolution)\n",
    "\n",
    "            if dist:\n",
    "                if len(person_width)<=2:\n",
    "\n",
    "                    person_width=get_pixel_scaler(results[0],person_width,resolution)\n",
    "\n",
    "                else:\n",
    "\n",
    "                    pixel_inch_scale=20/np.mean(person_width)\n",
    "                    cent=get_box_width(results[0],pixel_inch_scale)\n",
    "                    #frame=draw_dist(cent,frame)\n",
    "\n",
    "                    if len(results[0])>1:\n",
    "                        frame=compute_distance(frame,results[0],pixel_inch_scale)\n",
    "\n",
    "                    #np.mean(person_width)\n",
    "\n",
    "            if track:\n",
    "                #setting zero_sum to false disables the percent_cap counter reset\n",
    "                zero_sum=True\n",
    "                percent_cap=2.0\n",
    "                if not zero_sum:\n",
    "                    percent_cap=None\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                \n",
    "                trk.track_objects(results[0])\n",
    "                capacity_thresh=1\n",
    "                last_movement=(datetime.now()-trk.wait_times[-1][0]).total_seconds() if len(trk.wait_times)>0 else 0\n",
    "               \n",
    "                enter,exit=trk.count_reset(trk.totalUp,trk.totalDown,capacity_thresh,last_movement,percent_cap)\n",
    "                trk.totalUp,trk.totalDown=enter,exit\n",
    "\n",
    "                if trk.on_line_update: \n",
    "                    \n",
    "                    trk.wait_times.append([datetime.now(),trk.totalUp,trk.totalDown])\n",
    "                    trk.wait_times=trk.wait_times[-50:]\n",
    "                    \n",
    "                    fill_perc,fill_rate=trk.get_fill_values(enter,exit,capacity_thresh)\n",
    "                    \n",
    "                    wait=trk.get_wait_time(fill_perc,trk.wait_times)\n",
    "                    \n",
    "                    print('UP: {} DOWN: {}'.format(enter,exit))\n",
    "                    print( 'wait_time {}  fill% {}  occup {}/{}'.format(wait,fill_perc,fill_rate,capacity_thresh))\n",
    "                \n",
    "                    np.save('db/data.npy', np.array([datetime.now(),trk.totalUp,trk.totalDown]))\n",
    "                \n",
    "\n",
    "            if fps is not None:\n",
    "                fps.stop()\n",
    "                curr_fps=round(fps.fps(),2)\n",
    "\n",
    "            if draw:\n",
    "                frame=det.draw_boxes(frame,results,det.labels)    \n",
    "\n",
    "                if track:\n",
    "                    frame=trk.draw_tracking(frame)\n",
    "\n",
    "\n",
    "            if record:\n",
    "                vid.write(frame)\n",
    "            if display:\n",
    "                cv2.imshow('imgs',frame)            \n",
    "            if cv2.waitKey(1) == ord('q'):break \n",
    "\n",
    "    if record:\n",
    "        vid.release()\n",
    "        \n",
    "        output_split=os.path.splitext(output_path)\n",
    "        new_output_path='{}_{:.1f}{}'.format(output_split[0],fps.fps(),output_split[-1])\n",
    "        os.rename(output_path,new_output_path)\n",
    "        \n",
    "        \n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'streaming' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8c937a1e6c95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'outputs/{}/{}.avi'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideoname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'{}_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     streaming(video_path=video_path,resolution=resolution,color=color,\n\u001b[0m\u001b[0;32m     72\u001b[0m               \u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdet_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdet_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m               \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrack_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'streaming' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from streamutils import stream_video\n",
    "\n",
    "#video_path='videos/MW-18Mar-28.avi'\n",
    "\n",
    "#video_path='videos/kores_door.mp4'\n",
    "video_path='videos/video-4.mp4'\n",
    "\n",
    "#video_path='videos/MW-18Mar-17.avi'\n",
    "#video_path='videos/MW-18Mar-28.avi'\n",
    "#video_path='videos/MW-18Mar-3.avi'\n",
    "#video_path='videos/video_hard.avi'\n",
    "\n",
    "#video_path='videos/filename_16.mp4'\n",
    "\n",
    "#video_path='videos/MW-18Mar-26.mp4'\n",
    "#video_path='videos/MW-18Mar-20.avi'\n",
    "#video_path='videos/MW-18Mar-30.mp4'\n",
    "#video_path='videos/omni1B.avi'\n",
    "\n",
    "\n",
    "#streaming params\n",
    "\n",
    "track=True\n",
    "draw=True\n",
    "record=False\n",
    "display=False\n",
    "device='fps_test'\n",
    "#resolution=(300,240)\n",
    "resolution=(240,180)\n",
    "color=True\n",
    "\n",
    "#detection params\n",
    "\n",
    "#model_path='tf_models/omni_mobnet3_180_D75/detect_qt_16.tflite'\n",
    "\n",
    "model_path='tf_models/omni_mobnet3_240_v3/detect_qt_16.tflite'\n",
    "label_path='tf_models/omni_mobnet3_240_v3/labelmap.txt'\n",
    "\n",
    "model_kwargs={'model_path':model_path,'label_path':label_path}\n",
    "det_kwargs={'min_conf':.60,'max_boxes':10}\n",
    "\n",
    "\n",
    "#tracking params\n",
    "angle=0   \n",
    "\n",
    "#[x,y][x,y]\n",
    "line_points=[[0, 0.5], [0.8, 0.9]]\n",
    "\n",
    "\n",
    "#track_kwargs={'line_points':line_points,'buffer_frames':0,'maxDisappeared':3,'maxDistance':50}\n",
    "track_kwargs={'line_points':line_points,'buffer_frames':3,'maxDisappeared':5,'maxDistance':60}\n",
    "\n",
    "#fps\n",
    "new_fps=None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    output_path=None\n",
    "    if record:\n",
    "        if video_path is None:\n",
    "            videoname='sample'\n",
    "        else:\n",
    "            videoname=os.path.splitext(os.path.basename(video_path))[0]+'_'+device\n",
    "        \n",
    "        \n",
    "        folder=os.path.basename(os.path.split(model_path)[0])\n",
    "        filename= os.path.splitext(os.path.basename(model_path))[0]\n",
    "        output_path='outputs/{}/{}.avi'.format(videoname,'{}_{}'.format(folder,filename))\n",
    "\n",
    "    streaming(video_path=video_path,resolution=resolution,color=color,\n",
    "              model_kwargs=model_kwargs,det_kwargs=det_kwargs,\n",
    "              track=track,track_kwargs=track_kwargs,\n",
    "              output_path=output_path,display=display,draw=draw,new_fps=new_fps)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot call `vectorize` on size 0 inputs unless `otypes` is set",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-2145f677ea70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0menter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroom_thresh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlast_movement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmins_inactive\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpercent_cap\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mfill_perc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_fill_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroom_thresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mwait\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_wait_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfill_perc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m'wait_time {}  fill% {}  occup {}/{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_perc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfill_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mroom_thresh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-2145f677ea70>\u001b[0m in \u001b[0;36mget_wait_time\u001b[1;34m(fill_perc, wait_times, max_wait)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mwait_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwait_times\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mtime_diff\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwait_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m     \u001b[0mwait_time\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_diff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mwait_time\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mfill_perc\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mwait_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2091\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2159\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2161\u001b[1;33m             \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0motypes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2163\u001b[0m             \u001b[1;31m# Convert args to object arrays first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36m_get_ufunc_and_otypes\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   2115\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2117\u001b[1;33m                 raise ValueError('cannot call `vectorize` on size 0 inputs '\n\u001b[0m\u001b[0;32m   2118\u001b[0m                                  'unless `otypes` is set')\n\u001b[0;32m   2119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot call `vectorize` on size 0 inputs unless `otypes` is set"
     ]
    }
   ],
   "source": [
    "arr=[5,6]\n",
    "arr=[8,4]\n",
    "arr=[30,4]\n",
    "\n",
    "room_thresh=20\n",
    "\n",
    "mins_inactive=120\n",
    "percent_cap=2.0\n",
    "\n",
    "reset=False\n",
    "\n",
    "\n",
    "last_movement= 60#(datetime.now()-wait_time[-1][0]).total_seconds()\n",
    "\n",
    "\n",
    "\n",
    "def count_reset(enter,exit,thresh,last_movement,minutes_inactive=120,percent_cap=2.0,reset=False):\n",
    "    \n",
    "    if reset:\n",
    "        enter,exit=0,0\n",
    "    \n",
    "    \n",
    "    if mins_inactive and last_movement/60>=minutes_inactive:\n",
    "        enter,exit=0,0\n",
    "    \n",
    "    if percent_cap is not None:\n",
    "        #if percentage of exits exceeds the acceptable cap then counter is reset\n",
    "        if (enter-exit)/thresh < (-percent_cap):\n",
    "            enter,exit=0,0\n",
    "        #if percentage of entrance exceeds the acceptable cap then counter is capped to the threshold  \n",
    "        if (enter-exit)/thresh > percent_cap:\n",
    "            enter=thresh\n",
    "            exit=0\n",
    "    return enter,exit\n",
    "\n",
    "def get_fill_values(enter,exit,thresh):\n",
    "    \n",
    "    \n",
    "    fill_rate= max(0,enter-exit)\n",
    "    fill_perc=fill_rate/thresh\n",
    "\n",
    "    \n",
    "    return fill_perc,fill_rate\n",
    "\n",
    "\n",
    "def get_wait_time(fill_perc,wait_times,max_wait=3600):\n",
    "    wait_times=[i[0] for i in wait_times]\n",
    "    time_diff=np.diff(wait_times)\n",
    "    wait_time=np.median(np.vectorize(lambda x:x.total_seconds())(time_diff))\n",
    "    \n",
    "    wait_time= 0 if fill_perc<1 else wait_time\n",
    "    \n",
    "    return wait_time\n",
    "\n",
    "    \n",
    "enter,exit=count_reset(arr[0],arr[1],room_thresh,last_movement,mins_inactive,percent_cap,reset=reset)\n",
    "fill_perc,fill_rate=get_fill_values(enter,exit,room_thresh)\n",
    "wait=get_wait_time(fill_perc,wait_time)\n",
    "\n",
    "print( 'wait_time {}  fill% {}  occup {}/{}'.format(wait,fill_perc,fill_rate,room_thresh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video', 'image', 'model', 'detection', 'tracking', 'location', 'counter', 'db', 'credentials', 'other']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'record': 'True', 'draw': 'True', 'display': 'False', 'test': 'False'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
